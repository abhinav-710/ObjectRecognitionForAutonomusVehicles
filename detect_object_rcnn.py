# import the necessary packages
import cv2
import pickle
import config
import imutils
import argparse
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import img_to_array
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input


# construct the argument parser and parse the arguments
ap   = argparse.ArgumentParser()
ap.add_argument("-i", "--image", required=True,help="path to input image")
args = vars(ap.parse_args())

# load the our fine-tuned model and label binarizer from disk
print("[INFO] loading model and label binarizer...")
model = load_model(config.MODEL_PATH)
lb    = pickle.loads(open(config.ENCODER_PATH, "rb").read())

# load the input image from disk
image = cv2.imread(args["image"])

# run selective search on the image to generate bounding box proposal regions
print("[INFO] running selective search...")
ss    = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()
ss.setBaseImage(image)
ss.switchToSelectiveSearchFast()
rects = ss.process()

# initialize the list of region proposals that we'll be classifying along with their associated bounding boxes
proposals = []
boxes     = []

# loop over the region proposal bounding box coordinates generated by running selective search
for (x, y, w, h) in rects[:config.MAX_PROPOSALS]:
	
	# extract the region from the input image, convert it from BGR to RGB channel ordering, and then resize it to the required input dimensions of our trained CNN
	roi = image[y:y + h, x:x + w]
	roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)
	roi = cv2.resize(roi, config.INPUT_DIMS)
	
	# further preprocess the ROI
	roi = img_to_array(roi)
	roi = preprocess_input(roi)
	
	# update our proposals and bounding boxes lists
	proposals.append(roi)
	boxes.append((x, y, x + w, y + h))

# convert the proposals and bounding boxes into NumPy arrays
proposals = np.array(proposals, dtype="float32")
boxes     = np.array(boxes, dtype="int32")
print("[INFO] proposal shape: {}".format(proposals.shape))

# classify each of the proposal ROIs using fine-tuned model
print("[INFO] classifying proposals...")
proba     = model.predict(proposals)

# find the index of all predictions that are positive for the "vehicle" class
print("[INFO] applying NMS...")
labels    = lb.classes_[np.argmax(proba, axis=1)]
idxs      = np.where(labels == "vehicle")[0]

# use the indexes to extract all bounding boxes and associated class label probabilities associated with the "vehicle" class
boxes = boxes[idxs]
proba = proba[idxs][:, 1]

# further filter indexes by enforcing a minimum prediction probability be met
idxs  = np.where(proba >= config.MIN_PROBA)
boxes = boxes[idxs]
proba = proba[idxs]

# run non-maxima suppression on the bounding boxes
boxIdxs = tf.image.non_max_suppression(boxes,proba,config.COUNT_OF_DETECT,iou_threshold=config.IOU_THRESHOLD)

# loop over the bounding box indexes
for i in boxIdxs:
	
	(startX, startY, endX, endY) = boxes[i]
	if (endY-startY)<=(endX-startX)*2:
		# draw the bounding box, label, and probability on the image
		cv2.rectangle(image, (startX, startY), (endX, endY),(0, 255, 0), 2)
		y   = startY - 10 if startY - 10 > 10 else startY + 10
		text= " Vehicle"
		cv2.putText(image, text, (startX, y),cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 2)

# show the output image *after* running NMS
cv2.imshow("Detected Vehicles", image)
cv2.waitKey(0)
